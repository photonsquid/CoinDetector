{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recoinize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://github.com/nicknochnack/FaceRecognition](https://github.com/nicknochnack/FaceRecognition/blob/main/Facial%20Verification%20with%20a%20Siamese%20Network%20-%20Final.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Pull code from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers.cmd import git_update, print_gpu_name\n",
    "from src.helpers.install import install_requirements\n",
    "git_update(\"live-edit\", force=False, show_output=False)\n",
    "# install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A4000\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gpu_name()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard dependencies\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import tensorflow dependencies - Functional API\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src.models import make_embedding, make_siamese_model\n",
    "from src.helpers.setup import set_gpus_growth\n",
    "\n",
    "set_gpus_growth()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('photonsquid/coins-euro')\n",
    "dataset = dataset.with_format('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(file_path):\n",
    "\n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "\n",
    "    # Preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    # Scale image to be between 0 and 1\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img\n",
    "\n",
    "# we'll use the following function to create the pairs\n",
    "def create_pairs(x, y):\n",
    "    \"\"\"Create positive and negative pairs from two arrays\"\"\"\n",
    "    # create an empty list for the pairs\n",
    "    pairs = []\n",
    "    # create an empty list for the labels\n",
    "    labels = []\n",
    "    # create a list of unique classes\n",
    "    classes = np.unique(y)\n",
    "    # loop over the classes\n",
    "    for c in classes:\n",
    "        # find the indices of the images with the current class\n",
    "        idx = np.where(y == c)[0]\n",
    "        # loop over the indices\n",
    "        for i in range(len(idx)):\n",
    "            # get the current index\n",
    "            z1, z2 = idx[i], idx[(i + 1) % len(idx)]\n",
    "            # add the pair to the list of pairs\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            # add the label to the list of labels\n",
    "            inc = random.randrange(1, len(classes))\n",
    "            dn = (c + inc) % len(classes)\n",
    "            labels += [c == dn]\n",
    "    # convert the pairs and labels to numpy arrays\n",
    "    pairs = np.array(pairs)\n",
    "    labels = np.array(labels)\n",
    "    # return the pairs and labels\n",
    "    return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "train_dataset['image'].map(preprocess)\n",
    "test_dataset['image'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pairs and labels for the training dataset\n",
    "train_pairs, train_labels = create_pairs(\n",
    "    train_dataset['image'], train_dataset['label'])\n",
    "\n",
    "# create the pairs and labels for the testing dataset\n",
    "test_pairs, test_labels = create_pairs(\n",
    "    test_dataset['image'], test_dataset['label'])\n",
    "\n",
    "# prepare the dataset for training\n",
    "train_dataset = train_dataset.shuffle(1000)\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# prepare the dataset for testing\n",
    "test_dataset = test_dataset.shuffle(1000)\n",
    "test_dataset = test_dataset.batch(32)\n",
    "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
