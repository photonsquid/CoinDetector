{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recoinize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Pull code from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching origin\n",
      "Branch 'live-edit' set up to track remote branch 'live-edit' from 'origin'.\n",
      "Switched to a new branch 'live-edit'\n",
      "HEAD is now at a1dafff c:\\Users\\bsodium\\Code\\GitHub\\Recoinize\\.vscode\\settings.json updated\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git fetch --all\n",
    " \n",
    "# Switch to the \"live-edit\" branch, ignore local changes, and pull the latest changes\n",
    "!git checkout live-edit\n",
    "!git reset --hard\n",
    "!git pull\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Define constants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings are in the top of the notebook, so you can easily change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_IMAGES = 1000\n",
    "DATA_FOLDER = 'data'\n",
    "OUT_FOLDER = 'out'\n",
    "FOLDER_NAMES = ['positive', 'negative', 'anchor']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.install import install_requirements\n",
    "\n",
    "install_requirements()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 06:42:44.538821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 06:42:45.537677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-19 06:42:45.537791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-19 06:42:45.537801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import standard dependencies\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import tensorflow dependencies - Functional API\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Set GPU Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Define folder structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This folder names are defined in our script (cf. this [repo](https://github.com/photonsquid/Recoinize-generator)) that generates the dataset.\n",
    "Then it is uploaded to our [Hugging Face dataset](https://huggingface.co/datasets/photonsquid/coins-euro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATHS = {folder: os.path.join(DATA_FOLDER, folder) for folder in FOLDER_NAMES}\n",
    "\n",
    "# Create folders if they don't exist\n",
    "for folder in FOLDER_PATHS.values():\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the `FOLDER_PATHS` variable looks like:\n",
    "\n",
    "```python\n",
    "FOLDER_PATHS = {\n",
    "    \"positive\": \"data/positive\",\n",
    "    \"negative\": \"data/negative\",\n",
    "    \"anchor\": \"data/anchor\",\n",
    "}\n",
    "```\n",
    "\n",
    "At this point, the folders exist, but they are empty."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Download data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is not already done, download data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement it with huggin face library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have downloaded all the dataset, and we should have the following folder structure:\n",
    "\n",
    "```bash\n",
    "data\n",
    "├── negative\n",
    "│   ├── va_2euro_01.jpg\n",
    "│   ├── va_2euro_02.jpg\n",
    "│   ├── va_2euro_03.jpg\n",
    "│   ...\n",
    "├── positive\n",
    "│   ├── at_2euro_00.jpg\n",
    "│   ├── at_2euro_01.jpg\n",
    "│   ├── at_2euro_02.jpg\n",
    "│   ...\n",
    "└── anchor\n",
    "    ├── fr_2euro_00.jpg\n",
    "    ├── fr_2euro_01.jpg\n",
    "    ├── fr_2euro_02.jpg\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Load data into TensorFlow Datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take `n` images from each folder in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {tf.data.Dataset.list_files(FOLDER_PATHS[folder]+'\\*.jpg').take(NB_OF_IMAGES) for folder in FOLDER_NAMES}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7b1bd483bda95d85490d26c69d27f765d2de4e983a7d70cf38826b77b475eb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
